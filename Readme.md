#  KNN Paralelo con MPI 

Este proyecto implementa y eval√∫a una versi√≥n paralela del algoritmo
*k*-Nearest Neighbors utilizando `mpi4py` en Python. El trabajo forma parte del
curso Computaci√≥n Paralela y Distribuida (UTEC).

üìÑ Informe completo ‚Üí `Informe.pdf`  
üìä Resultados experimentales ‚Üí carpeta `par/digits/`

---

## Objetivo

Acelerar el proceso de clasificaci√≥n mediante paralelizaci√≥n del c√°lculo de
distancias entre muestras. Se mide:

- Tiempo total, c√≥mputo y comunicaci√≥n
- Speedup, eficiencia y FLOPs/s
- Validaci√≥n del modelo con un ajuste te√≥rico basado en el DAG del algoritmo
- Precisi√≥n del modelo (accuracy) con distintos valores de `p` y `N`

---

## Dataset utilizado

- Dataset: `digits` ‚Äî scikit-learn
- Tama√±os probados: `N = 200, 500, 1000, 1500, 1797`
- Dimensi√≥n de cada imagen: `d = 64`
- Vecinos: `k = 3`

> Se hicieron pruebas preliminares con `MNIST`, pero la mejora no se mantuvo en alto n√∫mero de procesos, por lo que el an√°lisis final se centr√≥ en `digits`.

---

## Ejecuci√≥n

### Versi√≥n secuencial
```bash
python3 sec/knn_digits_sec.py
```

### Versi√≥n paralela (MPI)

```bash
mpiexec --oversubscribe -n 32 \
    python3 par/digits/knn_digits_mpi_timed.py \
    --n_samples 1797 --k 3 --m 7 --csv knn_results.csv
```

### Par√°metros

| Flag        | Descripci√≥n |
|------------|-------------|
| `--n_samples` | tama√±o del dataset |
| `--k`         | n√∫mero de vecinos |
| `--m`         | repeticiones para promediar tiempos |
| `--csv`       | guarda resultados |

---

### Conclusiones principales

- El c√°lculo de distancias de KNN es altamente paralelizable y se logr√≥ una mejora significativa en rendimiento para tama√±os de datos medianos y grandes.
- Para el dataset completo `digits` (N = 1797), el mejor tiempo de ejecuci√≥n se obtuvo alrededor de **p ‚âà 32 procesos**, con speedup cercano a 12x y buena eficiencia.
- El **accuracy** se mantuvo constante para todos los valores de `p`, lo que demuestra que la paralelizaci√≥n no altera el resultado del clasificador respecto a la versi√≥n secuencial.
- La eficiencia y el rendimiento disminuyen a partir de **p ‚â• 64**, debido al incremento del costo de comunicaci√≥n y la menor carga de trabajo por proceso.
- Para tama√±os peque√±os (N = 200, 500), la paralelizaci√≥n **no es recomendable**, ya que la sobrecarga supera al c√≥mputo √∫til.
- El algoritmo muestra **buena escalabilidad** siempre que el tama√±o del problema crezca proporcionalmente al n√∫mero de procesos (aprox. N = Œò(p)).

