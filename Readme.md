# KNN paralelo 


## ğŸ“Œ Resumen ejecutivo
Este informe resume la paralelizaciÃ³n del algoritmo KNN sobre los datasets digits y MNIST, la metodologÃ­a experimental, la derivaciÃ³n teÃ³rica de FLOPs, la normalizaciÃ³n con datos experimentales, mÃ©tricas (tiempos totales, cÃ³mputo, comunicaciÃ³n), speedup, FLOPs/s y conclusiones.  

**Datos experimentales empleados:** `par/digits/knn_results.csv` (experimentos para N = 200, 500, 1000, 1500, 1797; p variando hasta 80).  

**ConclusiÃ³n principal:** la operaciÃ³n de cÃ¡lculo de distancias es altamente paralelizable. Sin embargo, el rendimiento real se ve limitado por la comunicaciÃ³n y el overhead de serializaciÃ³n en mpi4py/Python. Para N grande (ej. N=1797) el tiempo mÃ­nimo observado se alcanza alrededor de **p=32**; la eficiencia disminuye al aumentar p debido a sobrecostes de comunicaciÃ³n.

---

## ğŸ“‘ Ãndice  
1. Objetivo y alcance  
2. ImplementaciÃ³n y decisiones de paralelizaciÃ³n  
3. Conteo de FLOPs y modelo teÃ³rico  
4. Protocolo experimental y mÃ©tricas  
5. Resultados experimentales  
6. Speedup, eficiencia y p Ã³ptimo  
7. FLOPs/s y discusiÃ³n  
8. ComparaciÃ³n con Amdahl  
9. Conclusiones y recomendaciones  
10. Anexos: comandos para reproducir  

---

## 1. ğŸ§  Objetivo y alcance
- **Objetivo:** paralelizar KNN (clasificaciÃ³n supervisada) con mpi4py; medir tiempos (total, cÃ³mputo, comunicaciÃ³n), comparar con la versiÃ³n secuencial y validar con un modelo teÃ³rico basado en FLOPs.
- **Alcance:** cÃ³digo del repositorio (`sec/`, `par/`) y resultados guardados en CSV/PNG en `par/`.

---

## 2. ğŸ§© ImplementaciÃ³n y decisiones de paralelizaciÃ³n

**Scripts principales:**
| Tipo | Script |
|------|-------|
| Secuencial | `sec/knn_digits_sec.py` |
| MPI (Digits) | `par/digits/knn_digits_mpi.py` / `knn_digits_mpi_timed.py` |

**Estrategias MPI probadas:**
| Variante | DescripciÃ³n | Uso |
|----------|-------------|-----|
| 1 | `broadcast(train)` + `scatter(test)` | MÃ¡s usada â€” cada proceso tiene TODO el train y su porciÃ³n del test |
| 2 | `scatter(train)` + `broadcast(test)` | Ãštil para combinar vecinos locales y luego hacer gather |

**Primitivas:** `comm.bcast`, `comm.scatter`, `comm.gather`, `MPI.Barrier`, `MPI.Wtime`.  
**MediciÃ³n:** tiempos separados por regiÃ³n usando `MPI.Wtime()`.

---

## 3. ğŸ“ Conteo de FLOPs y modelo teÃ³rico

### FLOPs por distancia euclidiana (dimensiÃ³n d):
FLOP_pair â‰ˆ 3 Â· d (restas + multiplicaciones + sumas + sqrt)

shell
Copiar cÃ³digo

### Total para la parte paralelizable:
FLOP_total â‰ˆ 3 Â· d Â· n_train Â· n_test
con: n_train â‰ˆ 0.8Â·N , n_test â‰ˆ 0.2Â·N

shell
Copiar cÃ³digo

### Modelo de tiempo:
compute_time_teo(p) = FLOP_total / (p Â· peak_flops_por_nodo)
comm_time_teo(p) â‰ˆ Î±(pâˆ’1) + Î² Â· message_size(p)

markdown
Copiar cÃ³digo

**Peak estimado empÃ­ricamente desde p=1:**
peak â‰ˆ FLOP_total / compute_time(p=1)

yaml
Copiar cÃ³digo

---

## 4. ğŸ§ª Protocolo experimental y mÃ©tricas

- **Repeticiones:** `m=7` por punto en CSV.  
- **Semilla fija** para reproducibilidad.  
- **Barridos realizados:**
  - **Strong scaling:** N fijo, p âˆˆ {1,2,4,8,16,32,64,80}
  - **Weak scaling:** distintos N (scripts incluidos)

**MÃ©tricas registradas:**
| p | n_total | time_total | time_compute | time_comm | accuracy |

---

## 5. ğŸ“Š Resultados experimentales (resumen)

### ğŸ”¹ N = 200 â†’ FLOP_total = 1,228,800  
| p | total | compute | comm | accuracy |
|---|-------|---------|------|---------|
| 1 | 0.04579 | 0.04519 | 0.00060 | 0.95 |
| 16 | 0.00616 | 0.00434 | 0.00201 | 0.95 |

ğŸ“Œ **p Ã³ptimo ~16**

---

### ğŸ”¹ N = 1000 â†’ FLOP_total = 30,720,000  
| p | total | compute | comm | accuracy |
|---|-------|---------|------|---------|
| 1 | 1.11606 | 1.11329 | 0.00276 | 0.995 |
| 16 | 0.12011 | 0.10794 | 0.02687 | 0.995 |

---

### ğŸ”¹ N = 1797 â†’ FLOP_total â‰ˆ 99M  
| p | total | compute | comm | accuracy |
|---|-------|---------|------|---------|
| 1 | 3.92186 | 3.91640 | 0.00545 | ~0.983 |
| 32 | 0.28376 | 0.23172 | 0.11069 | ~0.983 |

ğŸ“Œ **Tiempo mÃ­nimo â‰ˆ p=32, eficiencia mayor en p=16**

---

## 6. âš™ï¸ Speedup, eficiencia y p Ã³ptimo

- **Speedup:** `S(p) = T1 / Tp`  
- **Eficiencia:** `E(p) = S(p) / p`  

### Tendencias:
- N pequeÃ±o â†’ el speedup cae rÃ¡pido por comunicaciÃ³n.  
- N grande â†’ p Ã³ptimo se desplaza hacia valores altos (mÃ¡s cÃ³mputo para paralelizar).

| N | p Ã³ptimo (tiempo) | p Ã³ptimo (eficiencia) |
|---|-------------------|------------------------|
| 200 | 16 | 8 |
| 1000 | 16 | 8 |
| 1797 | **32** | **16** |

---

## 7. âš¡ FLOPs/s y rendimiento

FLOPs/s â‰ˆ FLOP_total / time_compute

- Valores modestos: ~25â€“50 MFLOP/s (p=1)
- No representan el peak del hardware: Python + mpi4py aÃ±aden mucho overhead.
- Ãštiles solo para comparar implementaciones, NO para medir hardware real.

---

## 8. ğŸ“‰ ComparaciÃ³n con Amdahl

- fracciÃ³n paralelizable f â‰ˆ 0.99 (para N grande).  
- Amdahl predice mÃ¡s speedup del observado.
- **Causas de discrepancia:**
  - SerializaciÃ³n (pickling) en mpi4py.
  - Overhead de Python.
  - `np.array_split` produce desbalance.
  - ContenciÃ³n de cachÃ©/memoria.

---

## 9. Conclusiones y recomendaciones

### âœ” Conclusiones
- KNN **sÃ­ escala**, pero solo hasta cierto p.
- Para N=1797, **pâ‰ˆ32 minimiza tiempo total**, pero eficiencia cae.
- El cuello principal es **comunicaciÃ³n + serializaciÃ³n**.
